<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huang3&#39;s Noteble Online Book</title>
  <subtitle>Live to dream, make, and tell</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://feuerchop.github.io/"/>
  <updated>2016-10-21T13:35:46.000Z</updated>
  <id>http://feuerchop.github.io/</id>
  
  <author>
    <name>Huang Xiao, Ph.D</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Interview QA for Machine Learning Position</title>
    <link href="http://feuerchop.github.io/2016/10/21/inverview-qa-ml/"/>
    <id>http://feuerchop.github.io/2016/10/21/inverview-qa-ml/</id>
    <published>2016-10-21T13:07:43.000Z</published>
    <updated>2016-10-21T13:35:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>Here I list a set of Machine Learning questions &amp; answers for interview who wants to get a data scientist job or similar position.</p>
<p>Question List:</p>
<h4 id="Introduce-one-of-your-favorite-machine-learning-algorithms-in-detail"><a href="#Introduce-one-of-your-favorite-machine-learning-algorithms-in-detail" class="headerlink" title="Introduce one of your favorite machine learning algorithms in detail."></a>Introduce one of your favorite machine learning algorithms in detail.</h4><h4 id="How-would-you-evaluate-the-performance-of-your-classifier-Name-two-ways-at-least"><a href="#How-would-you-evaluate-the-performance-of-your-classifier-Name-two-ways-at-least" class="headerlink" title="How would you evaluate the performance of your classifier? Name two ways at least."></a>How would you evaluate the performance of your classifier? Name two ways at least.</h4><h4 id="How-would-you-understand-overfitting-and-what-you-can-do-about-it"><a href="#How-would-you-understand-overfitting-and-what-you-can-do-about-it" class="headerlink" title="How would you understand overfitting and what you can do about it?"></a>How would you understand overfitting and what you can do about it?</h4><h4 id="Tell-me-how-to-use-cross-validation-for-model-selection"><a href="#Tell-me-how-to-use-cross-validation-for-model-selection" class="headerlink" title="Tell me how to use cross validation for model selection."></a>Tell me how to use cross validation for model selection.</h4><h4 id="What’s-the-difference-of-ROC-and-PRC"><a href="#What’s-the-difference-of-ROC-and-PRC" class="headerlink" title="What’s the difference of ROC and PRC?"></a>What’s the difference of ROC and PRC?</h4><h4 id="What-is-cross-entropy-and-how-to-derive-it"><a href="#What-is-cross-entropy-and-how-to-derive-it" class="headerlink" title="What is cross entropy and how to derive it?"></a>What is cross entropy and how to derive it?</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Here I list a set of Machine Learning questions &amp;amp; answers for interview who wants to get a data scientist job or similar position.&lt;/p
    
    </summary>
    
      <category term="machine learning" scheme="http://feuerchop.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Introduction to Support Vector Clustering</title>
    <link href="http://feuerchop.github.io/2016/09/22/intro-svc/"/>
    <id>http://feuerchop.github.io/2016/09/22/intro-svc/</id>
    <published>2016-09-22T14:15:44.000Z</published>
    <updated>2016-10-21T13:07:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>支撑向量机（SVM）对熟悉机器学习的人来讲太不陌生了，90年代在神经网络逐渐衰败之际，出现一批以Vapinik为代表的统计学习理论研究者，其中代表作之一SVM大有一统江湖之意，如果不是深度学习网络的逆袭，我们恐怕以为机器学习就要这么走向终点。在深度网络以前，机器学习学界一直是以Graphical model和SVM为代表的贝叶斯和统计学习论两大流派占据了各大主流国际会议和论坛，尽管神经网络再一次以深度的姿态逆袭，我们会发现诸如SVM一类的经典算法仍然能够解决大部分我们遇到的问题。本文要介绍的就是SVM的一种变种算法：<em>支撑向量聚类（support vector clustering，SVC)</em>，如果你以为SVM只能用作监督学习的分类或者回归，那你就奥特了，SVM换一个形式也可以用作非监督的聚类，那么接下来我就为你揭开支撑向量聚类的神秘面纱。鉴于接下来将有一大波公式和图片袭来，请在家自行做好防护工作！</p>
<h3 id="问题描述和目标定义"><a href="#问题描述和目标定义" class="headerlink" title="问题描述和目标定义"></a>问题描述和目标定义</h3><p>问题是这样的，你不知道从哪里搞来了N条数据，每条数据有D个特征值，我们定义为</p>
<p>$$ \mathcal{X}=\left\lbrace x_1,\ldots, x_N\right\rbrace,\,\, x_i \in R^D, \forall i \in \left\lbrace 1,\ldots, N \right\rbrace $$<br>很可惜你只有数据却没有标签，那么监督学习算法基本你就放弃了。为了从数据当中学到点什么，我们可以采用聚类算法来探索数据在D维空间当中是怎么分布的，尽管没有标签用于监督学习，聚类算法仍然能够给你提供很多信息，例如哪些数据更相似，哪些数据属于异常。常用的聚类算法例如KNN，Kmean等都要求你确定具体的K值，即一开始你就假定数据大概可能分成K个簇，很显然，大部分的情况下你猜的都是错的，支撑向量聚类却没有这个问题，SVC的基本原理是这样描述的：</p>
<blockquote>
<p>散布在D维空间中的N个数据点，SVC聚类边界将该空间切割成两个部分，高密度部分包含了大部分的数据点，低密度部分只包含了少量异常数据点。</p>
</blockquote>
<p>在二维空间的实例中，我们可以从下图中看出SVC算法所做的事。</p>
<p><img src="http://img2.tbcdn.cn/L1/461/1/f1065371d7edf405ba45a104d47ec5db23a188f1.png" alt="screenshot"></p>
<p>上图中可以看到，聚类的边界最终将大部分的数据包括在内，而少量的明显异常的数据或噪音点责备排除在外，处于边界上的点我们称之为支撑向量，正是由于它们的存在才能够支撑其整个聚类边界。那么SVC是怎么做到的呢？</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;支撑向量机（SVM）对熟悉机器学习的人来讲太不陌生了，90年代在神经网络逐渐衰败之际，出现一批以Vapinik为代表的统计学习理论研究者，其中代表作之一SVM大有一统江湖之意，如果不是深度学习网络的逆袭，我们恐怕以为机器学习就要这么走向终点。在深度网络以前，机器学习学界一直
    
    </summary>
    
      <category term="research" scheme="http://feuerchop.github.io/categories/research/"/>
    
      <category term="machine learning" scheme="http://feuerchop.github.io/categories/research/machine-learning/"/>
    
    
      <category term="machine learning" scheme="http://feuerchop.github.io/tags/machine-learning/"/>
    
  </entry>
  
</feed>
