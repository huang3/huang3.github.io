<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta lang="zh-CN"><meta name="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Huang Xiao, Ph.D"><meta name="description" content="Welcome to this site, feel free to contact and spray critics"><title>Huang3's Noteble Online Book</title><link rel="icon" href="/favicon_h3.png"><link rel="canonical" href="http://feuerchop.github.io/"><link rel="alternate" href="/atom.xml" title="Huang3's Noteble Online Book"><link rel="stylesheet" href="/fonts/iconfont/iconfont.css"><link rel="stylesheet" href="/css/style.css"><script type="text/javascript"><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?Your baidu Analytics ID";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'Your Google Analytics ID', 'auto');
ga('send', 'pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div id="main"><header><a href="/." class="logo">Huang3's Noteble Online Book</a><ul class="nav"><li class="nav-link"><a href="/" class="active">Home</a></li><li class="nav-link"><a href="/tags/machine-learning" target="_self">Machine Learning</a></li><li class="nav-link"><a href="/tags/tech" target="_self">Tech.⧉技</a></li><li class="nav-link"><a href="/tags/misc" target="_self">杂谈</a></li><li class="nav-link"><a href="/archives/" target="_self">Archives</a></li><li class="nav-link"><a href="/about/" target="_self">About</a></li></ul></header><section id="container"><ul class="home"><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/10/23/botnet-detection/" class="post-link">Paper review - Botnet Detection</a></h2><span class="post-time">Oct 23, 2016</span><div class="post-content"><p>This blog is a summary of study for the paper as follows, figures and facts are derived from this paper and should not be abused for other purpose.</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><blockquote>
<p>Guofei Gu, Roberto Perdisci, Junjie Zhang, and Wenke Lee. 2008. <strong>BotMiner: clustering analysis of network traffic for protocol- and structure-independent botnet detection.</strong> In Proceedings of the 17th conference on Security symposium (SS’08). USENIX Association, Berkeley, CA, USA, 139-154.</p>
</blockquote>
<p>While machine learning has been proved effective enough in many different fields, notably such as NLP, OCR, recommendation system and so on, but its applications on Security is relatively barely satisfactory. Given that the security related data volume is booming up at a scale of GB-level per day in many organization, this is absolutely urgent to get our hands on the so called Data-Driven-Security. Amongst all, during my study over this subfield of applied machine learning, Botnets detection is actually a pretty good example or subject of research.</p>
<h3 id="A_few_words_about_Botnets"><a href="#A_few_words_about_Botnets" class="headerlink" title="A few words about Botnets"></a>A few words about Botnets</h3><p>A Botnet can be understood as a group of machines, infected or intended, communicated and controlled by a botmaster to carry on malicious activities through over the network. Obviously a botnet can perform serious harm on a legitimate network or system, known such as DDoS attacks, spams, phishing, identity theft and information exfiltration. Typical structure of Botnet can be centralized or distributed (P2P), and typical protocol of C&amp;C can be IRC, HTTP. Since HTTP is normally allowed by most of networks, HTTP-based P2P Botnet is getting more and more popular.</p>
<img src="https://www.usenix.org/legacy/event/sec08/tech/full_papers/gu/gu_html/img1.png" width="600">
<p><strong>Fig.1 Possible Botnet structures. (a) centralized (b) P2P</strong></p>
<p>Previous work has developed many techniques to detect Botnets, however, either focus on particular C&amp;C protocol, structure, infection model of botnets, or be incapable of dealing changing C&amp;C server addresses (e.g., fast-flux service network). In this paper, however, authors proposed a general data-drive framework based on intrinsic characteristics of botnets, namely,</p>
<ul>
<li>who is talking to whom? (C-plane)</li>
<li>who is doing what? (A-plane)</li>
</ul>
<p>The assumptions behind it is that we believe that an identifiable botnet is always driven by a certain number of C&amp;C servers, and is intended to perform malicious activities to some assets. Therefore, the characteristics of an identifiable botnet can be summarized as being C&amp;C patterns and the malicious activities patterns, as shown in Fig.1. By doing so, the detection framework is more independent of structure, protocols, infection models and so on, since we are inspecting the botnets by looking at its behavior.</p>
<h3 id="C-plane"><a href="#C-plane" class="headerlink" title="C-plane"></a>C-plane</h3><p>The BotMiner framework is thus divided into two parts, that is, C-plane and A-plane. C stands for C&amp;C which examines network flow between botmaster and bots, because it is believed the network flow between them follows some certain patterns. It helps logging the network flow in a format suitable for efficient storage and further analysis.</p>
<h3 id="A-plane"><a href="#A-plane" class="headerlink" title="A-plane"></a>A-plane</h3><p>On the other handside, A-plane focus on outbound traffic of activities performed by the bots. Suspicious activities such as scanning, spamming, binary downloading and exploit attempts could very possibly follow some certain patterns. To detect those malicious activities, they deployed a variety of IDS engines to identify the traffic patterns.</p>
<p>Importantly we note that either C-plane or A-plane is not enough to detect botnets, which can usually produce high false positive. BotMiner combines two planes and cross-correlate the outputs from both planes to produce the final results. The architecture of BotMiner is depicted in Fig.2.</p>
<p><img src="https://www.usenix.org/legacy/event/sec08/tech/full_papers/gu/gu_html/img2.png" alt="yy"></p>
<p><strong>Fig.2. BotMiner architecture</strong></p>
<h3 id="Learning_traffic"><a href="#Learning_traffic" class="headerlink" title="Learning traffic"></a>Learning traffic</h3><p>As seen in Fig.2, outbound traffic in A-plane and network flows data in C-plane will be filtered and preprocessed  to prepare vector-like features, just as commonly required by machine learning algorithms. For C-plane, similar network flow patterns are aggregated according to source IP and destination IP, also port number and protocol types, which define the <code>who is talking to whom</code>. Features are then built for example, number of flows per hour, number of packets per flow, avg. number of bytes per packets and avg. number of bytes per second. This characterizes the communication pattern when clients are talking to servers. Then a 2-step clustering is applied on the dataset, where X-means is used. For A-plane, it also follows 2-layer clustering, that is, Snort output are clustered firstly according to different types of activities, and further clustered within a similar activity. For instances, scanning on same ports will be classified as the same cluster. Overlapping of SMTP destinations will also be classified as the same cluster. This defines <code>who is doing what</code>. clustering results will be cross correlated to compute the final cluster result, which identifies the detected botnets. To confirm the cross-plane correlation, a score has to be assigned on host, where we expect higher score when the host belongs to multiple malicious activities. In the meanwhile, if the host also belongs to at least one C-cluster sharing a common network flow patterns, then we believe this host belongs to certain botnet.</p>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>The results look pretty good, BotMiner is able to detect almost all the botnets, detailed in Table.1.</p>
<table>
<thead>
<tr>
<th style="text-align:left">Botnet</th>
<th style="text-align:center">Number of Bots</th>
<th style="text-align:center">Detected?</th>
<th style="text-align:center">Clustered Bots</th>
<th style="text-align:center">Detection Rate</th>
<th style="text-align:center">False Positive Clusters/Hosts</th>
<th style="text-align:center">FP Rate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">IRC-rbot</td>
<td style="text-align:center">4</td>
<td style="text-align:center">YES</td>
<td style="text-align:center">4</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">1/2</td>
<td style="text-align:center">0.003</td>
</tr>
<tr>
<td style="text-align:left">IRC-sdbot</td>
<td style="text-align:center">4</td>
<td style="text-align:center">YES</td>
<td style="text-align:center">4</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">1/2</td>
<td style="text-align:center">0.003</td>
</tr>
<tr>
<td style="text-align:left">IRC-spybot</td>
<td style="text-align:center">4</td>
<td style="text-align:center">YES</td>
<td style="text-align:center">3</td>
<td style="text-align:center">75%</td>
<td style="text-align:center">1/2</td>
<td style="text-align:center">0.003</td>
</tr>
<tr>
<td style="text-align:left">IRC-N</td>
<td style="text-align:center">259</td>
<td style="text-align:center">YES</td>
<td style="text-align:center">258</td>
<td style="text-align:center">9.6%</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:left">HTTP-1</td>
<td style="text-align:center">4</td>
<td style="text-align:center">YES</td>
<td style="text-align:center">4</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">1/2</td>
<td style="text-align:center">0.003</td>
</tr>
<tr>
<td style="text-align:left">HTTP-2</td>
<td style="text-align:center">4</td>
<td style="text-align:center">YES</td>
<td style="text-align:center">4</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">1/2</td>
<td style="text-align:center">0.003</td>
</tr>
<tr>
<td style="text-align:left">P2P-Storm</td>
<td style="text-align:center">13</td>
<td style="text-align:center">YES</td>
<td style="text-align:center">13</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:left">P2P-Nugache</td>
<td style="text-align:center">82</td>
<td style="text-align:center">YES</td>
<td style="text-align:center">82</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
<p><strong>Table.1 Botnet detection results using BotMiner</strong></p>
<p>You can refer more explanation of the observations in the paper.</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Finally when we retrospect the work on detecting botnets using learning based techniques, it is believed and proved eventually that the assumptions made about the botnets are actually realistic and approchable. As we have seen, the whole frame work is grounded on two facts: <code>who is talking to whom</code> and <code>who is doing what</code>. Since we believe this characterizes the fundamental behavior of malware instances, which will be told apart from normal instances. Although a lot of effort on feature engineering is still indispensable for efficiency and precision, the intrinsic properties of botnets have shown those infected machines that have similar communication patterns, meanwhile perform the same set of multiple suspicious activities.</p>
</div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/10/23/icml15-review/" class="post-link">ICMl'15 Review</a></h2><span class="post-time">Oct 23, 2016</span><div class="post-content"><h3 id="Overall_comments"><a href="#Overall_comments" class="headerlink" title="Overall comments"></a>Overall comments</h3><p>Well organised in terms of main events, incl. presentations, posters, tutorials and workshops. However catering and services are kinda of being compromised due to a huge amount of visitors,  ~1600</p>
<img src="http://home.in.tum.de/~xiaohu/uploaded_images/ICML15-poster.jpg" width="760">
<h3 id="Research_topics"><a href="#Research_topics" class="headerlink" title="Research topics"></a>Research topics</h3><p>Covers almost a full spectrum of ML. topics, incl. DL., Opt., SL, USL, bandit, clustering, kernel methods, causality, time series, bayesian (nonparametric), privacy, large scale learning, distributed optimisation, RL, matrix factorisation, sparsity, transfer learning, ranking learning, networks and graphs, online learning, DL and vision, structured prediction,manifold learning, probe. models, variational inference, hashing, MC methods, FS., GP, approximate inference, NLP, sub modality, topic model, learning theory.</p>
<h3 id="Industry"><a href="#Industry" class="headerlink" title="Industry"></a>Industry</h3><p>Almost all the relevant companies are coming for recruiting people from ML. Alibaba has focus now on fraud detection, cloud computing, deep learning, and large scale learning. Google is hot as always. Microsoft is recruiting heavily all over the locations, amazon has its CEO from Germany coming to organize a premium lunch. Also e..g, twitter, disney research, nvidia, Baidu are all looking for top researchers of ML.</p>
<h3 id="People"><a href="#People" class="headerlink" title="People"></a>People</h3><p>Many top researchers are there, I met Schökopf, Bengio, Job Kleinberg, Leon Button, Emily fox, and also other amazing researchers.<br>Our paper got good feedbacks, some people showed their obvious interests on what we are doing. Adversarial learning is here an interesting topic, many people don’t know. Prof. Joachim in ETHZ is doing kinda of similar work as us, evaluating robustness of ML. algorithms using MI, his student would like to connect for future collaboration.<br>Also students from EPFL, Standfords, JHU, are also interested at our work, definitely gonna stay in touch.<br>Some people from Germany e.g., TUB, Humboldt, Max-plank institute (Bernhardt’s group), face detection company from Dresden. Cognitive system GmbH. Also many excellent researchers from China!</p>
</div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/10/22/git-multiple-sshkey/" class="post-link">How to setup multiple ssh keys for your github</a></h2><span class="post-time">Oct 22, 2016</span><div class="post-content"><p>The problem we faced usually when you deal with version control, is that, you probably have multiple github accounts and want to maintain various repositories accordingly. Say you have two github accounts: <strong>git_A</strong> and <strong>git_B</strong>, and you create repositories repo_a and repo_b under these two accounts.</p>
<p>Github usually will suggests you to generate your public key and associate them with your account. If you’re not familiar with ssh-keygen for github, please refer to <a href="https://help.github.com/articles/generating-an-ssh-key/" target="_blank" rel="external">this post</a>.</p>
<p>Now you need to generate two different public keys for <strong>git_A</strong> and <strong>git_B</strong>. This is what you expect when follow the ssh-keygen:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">YOURNAME$ ssh-keygen</div><div class="line">Generating public/private rsa key pair.</div><div class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/Users/YOURNAME/.ssh/id_rsa):</div></pre></td></tr></table></figure>
<p>This is where you name your public key, e.g., id_rsa_git_A.pub. Soon you will have two public keys in /Users/YOURNAME/.ssh/</p>
<p>Now let’s associate with your git accounts. Open your ssh config with any editor you like:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">YOURNAME$ vi ~/.ssh/config</div></pre></td></tr></table></figure></p>
<p>And add two sections accordingly in the config file:<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="selector-id">#github-A</span> accounts (default)</div><div class="line">Host github<span class="selector-class">.com-A</span></div><div class="line">    HostName github<span class="selector-class">.com</span></div><div class="line">    User git</div><div class="line">    IdentityFile ~/.ssh/id_rsa_git_A</div><div class="line"></div><div class="line"><span class="selector-id">#github-B</span> account</div><div class="line">Host github<span class="selector-class">.com-B</span></div><div class="line">    HostName github<span class="selector-class">.com</span></div><div class="line">    User git</div><div class="line">    IdentityFile ~/.ssh/id_rsa_git_B</div></pre></td></tr></table></figure></p>
<p>The name after <strong>Host</strong> can be any thing you like to identify your git account, obviously they are associated with different private keys here. Now you can test it with ssh, e.g.:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">YOURNAME$ ssh -T git@github.com-A</div></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">YOURNAME$ ssh -T git@github.com-B</div></pre></td></tr></table></figure>
<p>They should be automatically using corresponding public key now, and you will get successful message response.</p>
<p>To init and config a repository locally, you probably will do:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">YOURNAME$ git init</div><div class="line">YOURNAME$ git config user.name git_A</div><div class="line">YOURNAME$ git config user.email <span class="string">"git_A@your_mail_domain.com"</span></div><div class="line">YOURNAME$ git remote <span class="built_in">set</span>-url origin git@github.com-A:git_A/repo_a</div><div class="line">YOURNAME$ git pull origin</div></pre></td></tr></table></figure><br>That’s it! now you can do any git commands you want accordingly with different ssh keys.</p>
</div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/10/21/inverview-qa-ml/" class="post-link">Interview QA for Machine Learning Position</a></h2><span class="post-time">Oct 21, 2016</span><div class="post-content"><p>Here I list a set of Machine Learning questions &amp; answers for interview who wants to get a data scientist job or similar position.</p>
<p>Question List:</p>
<ul>
<li>Introduce one of your favorite machine learning algorithms in detail.</li>
<li>How would you evaluate the performance of your classifier? Name two ways at least.</li>
<li>How would you understand overfitting and what you can do about it?</li>
<li>Tell me how to use cross validation for model selection.</li>
<li>What’s the difference of ROC and PRC?</li>
<li>What is cross entropy and how to derive it?</li>
</ul>
</div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/09/22/intro-svc/" class="post-link">Introduction to Support Vector Clustering</a></h2><span class="post-time">Sep 22, 2016</span><div class="post-content"><p>支撑向量机（Support vector machine）对熟悉机器学习的人来讲太不陌生了，90年代在神经网络逐渐衰败之际，出现一批以Vapinik为代表的统计学习理论研究者，其中代表作之一SVM大有一统江湖之意，如果不是深度学习网络的逆袭，我们恐怕以为机器学习就要这么走向终点。在深度网络以前，机器学习学界一直是以probabilistic graphical model和SVM为代表的贝叶斯派和统计学习论两大流派占据了各大主流国际会议和论坛，尽管神经网络再一次以深度的姿态逆袭，我们仍然发现诸如SVM一类的经典算法仍然能够解决大部分我们遇到的分析问题，虽然由于其算法本质具有极高的局部特性。</p>
<p>本文要详细介绍的就是SVM的一种变种算法：支撑向量聚类（support vector clustering，SVC)，名字上显示是聚类，其实和Bernhardt的One-class SVM并没有两样，只不过是从另一个角度描述同一个问题而已，本质上是在学习数据在空间的密度（density）分布，然后再通过几何学的方法找出聚类边界，和SVM binary或者mulit-class分类不同，SVC是完全非监督的。</p>
<h3 id="u95EE_u9898_u63CF_u8FF0_u548C_u76EE_u6807_u5B9A_u4E49"><a href="#u95EE_u9898_u63CF_u8FF0_u548C_u76EE_u6807_u5B9A_u4E49" class="headerlink" title="问题描述和目标定义"></a>问题描述和目标定义</h3><p>我们首先这样定义问题，有 $N$ 条数据样本，每条数据有 $d$ 个特征值，我们定义为</p>
<span>$\mathcal{X}=\left\lbrace x_1,\ldots, x_N\right\rbrace,\,\, x_i \in R^d, \forall i \in \left\lbrace 1,\ldots, N \right\rbrace$</span><!-- Has MathJax -->
<p>很可惜你只有数据却没有标签，那么监督学习算法基本你就放弃了。为了从数据当中学到点什么，我们可以采用聚类算法来探索数据在D维空间当中是怎么分布的，尽管没有标签用于监督学习，聚类算法仍然能够给你提供很多信息，例如哪些数据更相似，哪些数据属于异常。常用的聚类算法例如KNN，Kmean等都要求你确定具体的K值，即一开始你就假定数据大概可能分成K个簇，很显然，大部分的情况下你猜的都是错的，支撑向量聚类却没有这个问题，SVC的基本原理是这样描述的：</p>
<blockquote>
<p>散布在D维空间中的N个数据点，SVC聚类边界将该空间切割成两个部分，高密度部分包含了大部分的数据点，低密度部分只包含了少量异常数据点。</p>
</blockquote>
<p>在二维空间的实例中，我们可以从下图中看出SVC算法所做的事。</p>
<p><img src="http://img2.tbcdn.cn/L1/461/1/f1065371d7edf405ba45a104d47ec5db23a188f1.png" alt="screenshot"></p>
<p>上图中可以看到，聚类的边界最终将大部分的数据包括在内，而少量的明显异常的数据或噪音点责备排除在外，处于边界上的点我们称之为支撑向量，正是由于它们的存在才能够支撑其整个聚类边界。那么SVC是怎么做到的呢？</p>
<h3 id="u6700_u5C0F_u8D85_u7403_u4F53"><a href="#u6700_u5C0F_u8D85_u7403_u4F53" class="headerlink" title="最小超球体"></a>最小超球体</h3><p>观察以上二维空间中数据分布，一种简单粗暴的聚类方法就是画一个尽可能小的圆把大部分的点都圈进去，可是和图中所示的聚类边界相比，这种方法明显过于粗放，并且数据的非线性分布不可能使一个圆恰巧把空间分割成高密度和低密度两部分。那么我们需要的是一个非线性的切割边界，借助于核函数（kernel function）我们能够有效的把低维非线性空间转换成高维的线性空间 $ \mathcal{H} $ ，这样一来，在 $ \mathcal{H} $ 空间里我们尝试着找到一个最小的超球体(hypersphere)将大部分的点包括进去，同时允许少量的异常点在球体外，这样映射回原来的低维空间就如我们上图所见的非线性的聚类边界。在大量的SVM文章中都谈及了核函数这个概念，下图简单的揭示了核函数的真正魅力所在，</p>
<img src="http://img2.tbcdn.cn/L1/461/1/d7d63dc8df47bdf5d72d450a104490b94b74906c.png" width="450" height="100" title="feature mapping from 1-d to 2-d">
<p>上图一组一维的数据，如果要进行有效的分类必须用两条线前后进行切割才能将红色和蓝色的点分开，然后如果我们对数据进行如下变换:  $\Phi(x)=(x,x^2)$ ，如右边所示，在映射之后的高维（2维）空间里，我们仅用一条直线就能很好的进行分类，即在低维空间线性不可分的数据在高维空间里变得线性可分了。这就是kernel function做的事，核函数的定义了一种特征变换 $\Phi(x)$ （实际上是空间变换），假设你希望寻找一个最优函数（e.g., 分类，聚类，回归）$ f(x)$, 根据<a href="https://en.wikipedia.org/wiki/Mercer%27s_theorem" target="_blank" rel="external">mercer’s theorem</a>, 你总能从核函数变换过的空间(Hilbert space)中寻找到一个最优函数 <span>$f^*$</span><!-- Has MathJax --> 使得该函数是映射后的点的线性叠加，即： $ f^*(.) = \sum_i c_i\Phi(x_i)$, 正是这种在 $ \mathcal{H} $ 空间中的线性特征使得核方法能够处理很多低维空间中的非线性问题，那么当你定义一个核函数为 <span>$k(x_i,x_j) = \left&lt;\Phi(x_i),\Phi(x_j)\right&gt;$</span><!-- Has MathJax --> ，实际上是定义了一个等价的特征空间并且该空间的内积是由 <span>$k(\cdot,\cdot)$</span><!-- Has MathJax --> 来定义的。此处不再做展开，感兴趣的朋友可以跟我联系。<br>那么回到之前的聚类问题，寻找低维空间非线性聚类边界的问题转换成了寻找高维空间中最小超球体的问题，</p>
<p>定义球体的半径$ R $和球心 $ \mathbf{a} $ , 还有一组松弛变量 $ \left\lbrace \xi_i \right\rbrace $ ，SVC问题如下：</p>
<span>$$\begin{align}
&amp; \min_{R} R^2+C\sum_i\xi_i \nonumber\\
\text{s.t. } &amp; \|\Phi(x_i) - \mathbf{a} \|^2 \leq R^2 + \xi_i \nonumber\\
&amp; \xi_i\geq 0, \, \forall i \in \left\lbrace 1,\ldots, N\right\rbrace \nonumber
\end{align}$$</span><!-- Has MathJax -->
<p>上述目标函数描述了两个问题，</p>
<ol>
<li>我们希望找到一个最小的超球半径和球心，使得大部分的点都在球内。</li>
<li>针对每一个数据点引入非负松弛变量 $ \xi_i $ 允许该样本在球体外部，但不至于离球心太远，常数 $C$ 是惩罚参数防止 $ \sum_i \xi_i $ 过大。</li>
</ol>
<p>很显然这是个 <strong>带限制条件的二次型问题</strong>。那么观察目标函数中的限制条件进一步告诉我们，如果一个点在球体内部，那么 $ \xi_i=0 $ ，否则如果它在球体外部（异常点），那么 $ \xi_i&gt;0 $ 。</p>
<h3 id="u4F18_u5316_u3001_u4F18_u5316_uFF0C_u8FD8_u662F_u4F18_u5316"><a href="#u4F18_u5316_u3001_u4F18_u5316_uFF0C_u8FD8_u662F_u4F18_u5316" class="headerlink" title="优化、优化，还是优化"></a>优化、优化，还是优化</h3><blockquote>
<p>所有的机器学习问题都是个优化问题</p>
</blockquote>
<p>一个学习问题如果能够完美定义，它总能够转化成一个形式优美的优化问题，如上面SVC的目标函数就是一个典型的不能再典型的凸优化问题了，二话不说直接上<a href="http://baike.baidu.com/link?url=WeZGD3nvabLVvd5C2igcjda8YbWF55uvH51TnG-YDBTv113jPlC4WrX1N-n6gVEEXmtD2uKkJpyGY4x8lCOS6_" target="_blank" rel="external">拉格朗日乘子法</a>。为每个限制条件引入拉格朗日乘子$\mathbf{\alpha}$ 和 $ \mathbf{\mu} $，得到</p>
<p>$$<br>L=R^2-\sum_j\left(R^2+\xi_j-|\Phi(x_j)-\mathbf{a}|^2\right)\alpha_j-\sum_j\xi_j\mu_j+\sum_j C\xi_j,<br>$$</p>
<p>如果$ L $有最优解，那么设置primal优化变量的梯度为0，我们得到，</p>
<p>$$<br>\sum\alpha_j=1, \,<br>\mathbf{a}=\sum\alpha_j\Phi(x_j), \,<br>\alpha_j=C-\mu_j<br>$$</p>
<p>并且KKT条件必须成立：</p>
<p>$$<br>\xi_j\mu_j=0, \,<br>\left(R^2+\xi_j-|\Phi(x_j)-\mathbf{a}|^2\right)\alpha_j=0<br>$$</p>
<p>将以上极值条件代回到$ L $当中，我们可以得到对偶空间的等价优化问题：<br>$$<br>\mathcal{W}=\sum_{i,j}\alpha_i\alpha_j k(x_i,x_j) - \sum_jk(x_j,x_j)\alpha_j, \qquad<br>\text{s.t.}\quad 0\leq\alpha_j\leq C, \; j=1,\ldots,N. \<br>$$</p>
<p>此处 <span>$k(x_i, x_j) = \left&lt;\Phi(x_i) \cdot \Phi(x_j)\right&gt;$</span><!-- Has MathJax --> , 和SVM问题如此的相似，原来的优化问题转化成了对偶空间里的带限制条件的 <strong>单变量二次型优化问题</strong>。接下来我们所要做的就是解这个优化问题。<br>在求解之前，我们不妨先来观察一下之前的极值条件。   </p>
<ol>
<li>首先，所有的 $ \alpha_i $ 加起来必须等于1.</li>
<li>其次，我们观察到最终的超球体球心即是所有映射后的数据点和 $ \mathbf{\alpha}$ 的线性加权组合，这点符合我们之前关于核函数空间的解释。</li>
<li>最终需要优化的拉格朗日乘子 $ \mathbf{\alpha} $ 分成三个集合:<ul>
<li>当 $ \alpha_i=0 $ 时，我们发现 $ \mu_i=C $ , 那么 $ \xi_i=0 $ ，即 $ x_i $ 必然在球内。</li>
<li>当 $ \xi_i&gt;0 $ 时，即 $ x_i $在球体外（异常点），那么我们知道 $ \mu_i=0$ 从而$ \alpha_i=C $</li>
<li>当 $ 0 &lt; \alpha_i &lt; C $ 时，$ \mu_i&gt;0 $ ，于是 $ \xi_i=0 $ ，并且 $ R^2-|\Phi(x_j)-\mathbf{a}|^2=0 $ , 也就是意味着 $ x_i $ 刚好在球体上，即支撑向量。</li>
</ul>
</li>
</ol>
<p>为了得到超球体的最优半径，我们从结果当中任意选取一个支撑向量 $ x_s $ ，它到球心的距离即是我们要找的最优半径。</p>
<span>$R^2 = \|\Phi(x_s) - \mathbf{a}\|^2 = k(x_s,x_s)-2\sum_j\alpha_j k(x_s,x_j) + \sum_{i,j}\alpha_i\alpha_j k(x_i,x_j)$</span><!-- Has MathJax -->
<p>并且任意一个点到球心的距离都可以通过该公式计算。此外，通过调节参数 $ C $ 的大小来惩罚松弛变量的值，我们可以控制异常数据在整个数据中所占的比例。<br>以上是SVC算法最重要的结论，当我们能够通过优化目标函数得到 $ \mathbf{\alpha} $ 时，我们就能够通过观察它们的值来确定究竟哪些点在球体内，球体上，和球体外，而那些落在超球体之外的点就是异常点，这个特性可以用在异常检测问题上。为了演示，在二维空间上的聚类效果如下图：</p>
<img src="http://img2.tbcdn.cn/L1/461/1/8912d3cc6d7f0d666d77b1f70a9ace393bc62b7d.png" width="550" title="Clustering boundary and density plot">
<p>除了左边所示能够判断一个数据落在什么位置之外，还能够对空间中任意一个点计算其到球心的距离来判断该点在空间中的概率密度如何（如右图）</p>
<h3 id="u4ECE_u805A_u7C7B_u8FB9_u754C_u5230_u805A_u7C7B_u6807_u7B7E"><a href="#u4ECE_u805A_u7C7B_u8FB9_u754C_u5230_u805A_u7C7B_u6807_u7B7E" class="headerlink" title="从聚类边界到聚类标签"></a>从聚类边界到聚类标签</h3><p>SVC优化后我们得到的是聚类边界，但为了得到具体的聚类标签，我们还需要对结果进行后续处理，通常我们采取的方法是，连接任意两个在超球体内的点，如果该直线片段上存在一个点属于超球体外，那么我们判断这两个点不属于一个簇，因为从一个点到另一个点必然经过了低密度区域，如下图所示。</p>
<table>
<thead>
<tr>
<th style="text-align:left">Clustering</th>
<th style="text-align:left">Line segmenting</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><img src="http://img2.tbcdn.cn/L1/461/1/a3c97754bbb7941343d22cd0512bf2e078c1c979.png" alt="screenshot"></td>
<td style="text-align:left"><img src="http://img2.tbcdn.cn/L1/461/1/32a0f29b38a670129080fd9465cd069531dfda3c.png" alt="screenshot"></td>
</tr>
</tbody>
</table>
<p>通过对最终结果两两之间连线进行采样并计算是否存在点在超球体外的方法可以帮助我们确定每个点所属的聚类标签。</p>
<h3 id="u5982_u4F55_u89E3_u4F18_u5316_u95EE_u9898"><a href="#u5982_u4F55_u89E3_u4F18_u5316_u95EE_u9898" class="headerlink" title="如何解优化问题"></a>如何解优化问题</h3><p>那么如何解上述的二次型优化问题，现在有很多开源的解二次型优化问题的包，但是针对SVM这一类的特定算法，这些包的效率通常都很低，目前最常用的一套算法SMO算法采取的类似坐标下降法可以很高效的解决这一类的优化问题，在后续文章里我们将重点介绍SMO算法。</p>
<h3 id="u7ED3_u675F_u8BED"><a href="#u7ED3_u675F_u8BED" class="headerlink" title="结束语"></a>结束语</h3><p>无论是异常检测还是聚类，SVC [1]都是一套非常实用的算法，其原理和One-class SVM [3] 非常的类似, 了解单类SVM算法的读者会发现换一种问题的形式化方式往往可以从另一个角度去解释一个学习问题。以上简单扼要的介绍了整个算法的理论基础，针对算法实现，尤其是优化部分会有后续文章跟进，如果你对该算法感兴趣欢迎联系交流！</p>
<h3 id="u53C2_u8003_u6587_u732E"><a href="#u53C2_u8003_u6587_u732E" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] H. Xiao and C. Eckert. Indicative support vector clustering with its application on anomaly detection. In IEEE 12th International Conference on Machine Learning and Applications (ICMLA’13), Miami, Florida, USA, December 2013.</p>
<p>[2] A. Ben-Hur, D. Horn, H. Siegelmann, and V. Vapnik. A support vector clustering method. In Pattern Recognition, 2000. Proceedings. 15th International Conference on, volume 2, pages 724–727 vol.2, 2000.</p>
<p>[3] B. Schoekopf, J. C. Platt, J. C. Shawe-Taylor, A. J. Smola, and R. C. Williamson. Estimating the support of a high-dimensional distribution. Neural Comput., 13(7):1443– 1471, July 2001.</p>
</div></article></li></ul><div class="paginator"></div></section><footer><div class="social"><a href="mailto:xh0217@gmail.com" title="email" class="iconfont icon-email"></a><a href="/feuerchop" title="twitter" class="iconfont icon-twitter"></a><a href="/feuerchop" title="github" class="iconfont icon-github"></a><a href="https://www.zhihu.com/people/huangsanxiao" title="zhihu" class="iconfont icon-zhihu"></a><a href="/atom.xml" title="rss" class="iconfont icon-rss"></a></div><div class="copyright"><p class="power">Powered by <a href="https://hexo.io/">Hexo</a> and Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p><p class="since">&copy;2016<span class="heart"><i class="iconfont icon-heart"></i></span><span class="author">Huang Xiao, Ph.D</span></p></div><label id="back2top"><i class="iconfont icon-up"></i></label></footer></div><script src="/js/zepto.min.js"></script><script src="/js/theme.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>